{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train grammar error detection model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from utils.logging import get_logger\n",
    "from utils.metrics import (\n",
    "    metric_seqeval,\n",
    "    metric_matthews_correlation,\n",
    "    metric_exact_match,\n",
    ")\n",
    "from helper_model import GER_MODEL, GER_DIRECTORY\n",
    "from prepare_ger_dataset import load_ger_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get logger\n",
    "train_ger_model = get_logger(\"Train GER model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MODEL_CHECKPOINT = \"EMBEDDIA/sloberta\"\n",
    "MODEL_NAME = GER_MODEL\n",
    "BATCH_SIZE = 16  # 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GER dataset\n",
    "dataset = load_ger_dataset(GER_DIRECTORY)\n",
    "label_list = dataset[\"train\"].features[\"ger_tags\"].feature.names\n",
    "train_ger_model.info(\"{} dataset read\".format(MODEL_NAME))\n",
    "\n",
    "# Compute class weights\n",
    "outputs = [\n",
    "    *sum(dataset[\"train\"][\"ger_tags\"], []), \n",
    "    *sum(dataset[\"test\"][\"ger_tags\"], []), \n",
    "    *sum(dataset[\"validation\"][\"ger_tags\"], [])\n",
    "]\n",
    "CLASS_WEIGHTS = [*class_weight.compute_class_weight(\n",
    "    'balanced', \n",
    "    classes=np.unique(outputs), \n",
    "    y=outputs\n",
    ")]\n",
    "\n",
    "# Create the tokenizer and the model for our model (SloBERTa)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT, use_fast=True)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL_CHECKPOINT, num_labels=len(label_list)\n",
    ")\n",
    "train_ger_model.info(\"{} model and tokenizer initialized\".format(MODEL_NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the code device-agnostic\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transferring the model to a CUDA enabled GPU\n",
    "model = model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(data):\n",
    "    \"\"\"\n",
    "    Tokenize sentences with specific tokenizer which suits our model. Tokenizer\n",
    "    will tokenize text inputs and put it in a format the model excepts, as well\n",
    "    as generate the other inputs that model generates\n",
    "\n",
    "    NB: we use truncation to ensure that the input longer than what the model\n",
    "    can handle will be truncated to the maximum length accepted by the model.\n",
    "    NB: our inputs have already been split into words, that is why we use\n",
    "    is split into words flag -> there may be a case, where our words will be\n",
    "    split into subwords, which means we also need to process that (word_ids)\n",
    "    NB: we used batched processing to leverage the full benefit of the fast\n",
    "    tokenizer.\n",
    "\n",
    "    @param data: the data we want to tokenize\n",
    "    @return: tokenized data with a specific model required tokenizer\n",
    "    \"\"\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        data[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(data[\"ger_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to\n",
    "            # -100 so they are automatically ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the\n",
    "            # current label or -100, depending on the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tokenize function on all the sentences in our dataset\n",
    "encoded_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Setup the training arguments\n",
    "args = TrainingArguments(\n",
    "    output_dir=MODEL_NAME,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    auto_find_batch_size=True,\n",
    "    report_to=\"all\",\n",
    "    deepspeed=\"./deepspeed_config.json\",\n",
    ")\n",
    "\n",
    "# Data collator, which will pad the tokens and labels to make them all the same size\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Get a predictions, which need to be evaluated, and evaluate them with specific\n",
    "    metric.\n",
    "\n",
    "    @param eval_pred: the predictions, which needs to be evaluated\n",
    "    @return: evaluation score\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    seqeval = metric_seqeval.compute(\n",
    "        predictions=true_predictions, references=true_labels\n",
    "    )\n",
    "\n",
    "    matthews_correlation = np.mean(\n",
    "        [\n",
    "            metric_matthews_correlation.compute(\n",
    "                predictions=prediction, references=label\n",
    "            )[\"matthews_correlation\"]\n",
    "            for prediction, label in zip(predictions, labels)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    exact_match = np.mean(\n",
    "        [\n",
    "            metric_exact_match.compute(predictions=prediction, references=label)[\n",
    "                \"exact_match\"\n",
    "            ]\n",
    "            for prediction, label in zip(true_predictions, true_labels)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"precision\": seqeval[\"overall_precision\"],\n",
    "        \"recall\": seqeval[\"overall_recall\"],\n",
    "        \"f1\": seqeval[\"overall_f1\"],\n",
    "        \"accuracy\": seqeval[\"overall_accuracy\"],\n",
    "        \"matthews_correlation\": matthews_correlation,\n",
    "        \"exact_match\": exact_match,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    \"\"\"\n",
    "    Create a model for sequence classification with two labels.\n",
    "    @return: a model, which we will fine tune\n",
    "    \"\"\"\n",
    "    return AutoModelForTokenClassification.from_pretrained(\n",
    "        MODEL_CHECKPOINT, num_labels=len(label_list)\n",
    "    ).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom GER trainer, which will use class weights\n",
    "class GERTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_function = torch.nn.CrossEntropyLoss(\n",
    "            # This needs to be hardcoded (CLASS_WEIGHTS)\n",
    "            weight=torch.tensor([\n",
    "                0.030780315367896285,\n",
    "                87.74089259625806,\n",
    "                70.87612303943962,\n",
    "                164.9631401736665,\n",
    "                123.9942723942724,\n",
    "                143.19135517612676,\n",
    "                143.19135517612676,\n",
    "                18.73709529704216,\n",
    "                180.24726498208926,\n",
    "                424.1909318751424,\n",
    "                94.81914947797301,\n",
    "                88.2901313605539,\n",
    "                88.98642577191472,\n",
    "                125.37198653198654,\n",
    "                158.47582567245487,\n",
    "                339.8638189120117,\n",
    "                462.4376552409339,\n",
    "                1175.3623737373737,\n",
    "                42.38722309496164,\n",
    "                276.55585264408796,\n",
    "                23.73470506495328,\n",
    "                2089.533108866442,\n",
    "                11.105786208542114,\n",
    "                27.400385594654658,\n",
    "                63.177372832468016,\n",
    "                50.59855958690039,\n",
    "                42.45101124107896,\n",
    "                2089.533108866442,\n",
    "                633.9033026898195,\n",
    "                17.153357841104878,\n",
    "                94.34346812607683,\n",
    "                122.64650856389987,\n",
    "                64.92220246190327,\n",
    "                2256.6957575757574\n",
    "            ]).to(DEVICE)\n",
    "        )\n",
    "        loss = loss_function(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search\n",
    "trainer = GERTrainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "train_ger_model.info(\"{} trainer initialized\".format(MODEL_NAME))\n",
    "\n",
    "# Find most optimal parameters for our model\n",
    "train_ger_model.info(\"{} GER hyperparameter search started\".format(MODEL_NAME))\n",
    "hyperparameters = trainer.hyperparameter_search(direction=\"maximize\")\n",
    "train_ger_model.info(\"{} GER hyperparameter search ended\".format(MODEL_NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use most optimal parameters\n",
    "for name, value in hyperparameters.hyperparameters.items():\n",
    "    setattr(trainer.args, name, value)\n",
    "train_ger_model.info(\"Hyperparameters: {}\".format(hyperparameters.hyperparameters))\n",
    "\n",
    "# Fine tune the model for GER task\n",
    "train_ger_model.info(\"{} model training started\".format(MODEL_NAME))\n",
    "trainer.train()\n",
    "train_ger_model.info(\"{} model training ended\".format(MODEL_NAME))\n",
    "\n",
    "# Check if the trainer did reload the best model and not the last\n",
    "train_ger_model.info(trainer.evaluate())\n",
    "\n",
    "# Save the model so it can be reloaded with from_pretrained()\n",
    "trainer.save_model(MODEL_NAME)\n",
    "train_ger_model.info(\"{} model saved\".format(MODEL_NAME))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('slovko')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b7441cdf19e0d28b58859c3a7d82aad7fb7437a4f6af83da442de25c6af8e16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
