{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train grammar error detection model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from utils.logging import get_logger\n",
    "from utils.metrics import (\n",
    "    metric_accuracy,\n",
    "    metric_precision,\n",
    "    metric_recall,\n",
    "    metric_f1,\n",
    "    metric_matthews_correlation,\n",
    ")\n",
    "from helper_model import GED_MODEL, GED_DIRECTORY\n",
    "from prepare_ged_dataset import load_ged_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get logger\n",
    "train_ged_model = get_logger(\"Train GED model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MODEL_CHECKPOINT = \"EMBEDDIA/sloberta\"\n",
    "MODEL_NAME = GED_MODEL\n",
    "BATCH_SIZE = 16  # 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GED dataset\n",
    "dataset = load_ged_dataset(GED_DIRECTORY)\n",
    "train_ged_model.info(\"{} dataset read\".format(MODEL_NAME))\n",
    "\n",
    "# Compute class weights\n",
    "outputs = [\n",
    "    *dataset[\"train\"][\"label\"], \n",
    "    *dataset[\"test\"][\"label\"], \n",
    "    *dataset[\"validation\"][\"label\"]\n",
    "]\n",
    "CLASS_WEIGHTS = [*class_weight.compute_class_weight(\n",
    "    'balanced', \n",
    "    classes=np.unique(outputs), \n",
    "    y=outputs\n",
    ")]\n",
    "\n",
    "# Create the tokenizer and the model for our model (SloBERTa)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_CHECKPOINT, num_labels=2\n",
    ")\n",
    "train_ged_model.info(\"{} model and tokenizer initialized\".format(MODEL_NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the code device-agnostic\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transferring the model to a CUDA enabled GPU\n",
    "model = model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(data):\n",
    "    \"\"\"\n",
    "    Tokenize sentences with specific tokenizer which suits our model. Tokenizer\n",
    "    will tokenize text inputs and put it in a format the model excepts, as well\n",
    "    as generate the other inputs that model generates\n",
    "\n",
    "    NB: we use truncation to ensure that the input longer than what the model\n",
    "    can handle will be truncated to the maximum length accepted by the model.\n",
    "    NB: we used batched processing to leverage the full benefit of the fast\n",
    "    tokenizer.\n",
    "\n",
    "    @param data: the data we want to tokenize\n",
    "    @return: tokenized data with a specific model required tokenizer\n",
    "    \"\"\"\n",
    "    return tokenizer(data[\"sentence\"], truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tokenize function on all the sentences in our dataset\n",
    "encoded_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Setup the training arguments\n",
    "args = TrainingArguments(\n",
    "    output_dir=MODEL_NAME,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    auto_find_batch_size=True,\n",
    "    report_to=\"all\",\n",
    "    deepspeed=\"./deepspeed_config.json\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Get a predictions, which need to be evaluated, and evaluate them with specific\n",
    "    metric.\n",
    "\n",
    "    @param eval_pred: the predictions, which needs to be evaluated\n",
    "    @return: evaluation score\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    accuracy = metric_accuracy.compute(predictions=predictions, references=labels)[\n",
    "        \"accuracy\"\n",
    "    ]\n",
    "    precision = metric_precision.compute(predictions=predictions, references=labels)[\n",
    "        \"precision\"\n",
    "    ]\n",
    "    recall = metric_recall.compute(predictions=predictions, references=labels)[\"recall\"]\n",
    "    f1 = metric_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "    matthews_correlation = metric_matthews_correlation.compute(\n",
    "        predictions=predictions, references=labels\n",
    "    )[\"matthews_correlation\"]\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"matthews_correlation\": matthews_correlation,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    \"\"\"\n",
    "    Create a model for sequence classification with two labels.\n",
    "    @return: a model, which we will fine tune\n",
    "    \"\"\"\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_CHECKPOINT, num_labels=2\n",
    "    ).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom GED trainer, which will use class weights\n",
    "class GEDTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_function = torch.nn.CrossEntropyLoss(\n",
    "            # This needs to be hardcoded (CLASS_WEIGHTS)\n",
    "            weight=torch.tensor([1.514000662150461, 0.7465481624733931]).to(DEVICE)\n",
    "        )\n",
    "        loss = loss_function(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search\n",
    "trainer = GEDTrainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "train_ged_model.info(\"{} trainer initialized\".format(MODEL_NAME))\n",
    "\n",
    "# Find most optimal parameters for our model\n",
    "train_ged_model.info(\"{} GED hyperparameter search started\".format(MODEL_NAME))\n",
    "hyperparameters = trainer.hyperparameter_search(direction=\"maximize\")\n",
    "train_ged_model.info(\"{} GED hyperparameter search ended\".format(MODEL_NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use most optimal parameters\n",
    "for name, value in hyperparameters.hyperparameters.items():\n",
    "    setattr(trainer.args, name, value)\n",
    "train_ged_model.info(\"Hyperparameters: {}\".format(hyperparameters.hyperparameters))\n",
    "\n",
    "# Fine tune the model for GED task\n",
    "train_ged_model.info(\"{} model training started\".format(MODEL_NAME))\n",
    "trainer.train()\n",
    "train_ged_model.info(\"{} model training ended\".format(MODEL_NAME))\n",
    "\n",
    "# Check if the trainer did reload the best model and not the last\n",
    "train_ged_model.info(trainer.evaluate())\n",
    "\n",
    "# Save the model so it can be reloaded with from_pretrained()\n",
    "trainer.save_model(MODEL_NAME)\n",
    "train_ged_model.info(\"{} model saved\".format(MODEL_NAME))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('slovko')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b7441cdf19e0d28b58859c3a7d82aad7fb7437a4f6af83da442de25c6af8e16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
