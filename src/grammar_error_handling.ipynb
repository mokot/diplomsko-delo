{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar Error Handling\n",
    "\n",
    "This file represents the whole pipeline for grammar error handling. This includes:\n",
    "- Text preprocessing\n",
    "- Sloleks component\n",
    "- Grammar Error Detection (GED)\n",
    "- Grammar Error Recognition (GER)\n",
    "- Grammar Error Correction (GEC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from train_model.utils.logging import get_logger\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    TextClassificationPipeline,\n",
    "    TokenClassificationPipeline,\n",
    "    Text2TextGenerationPipeline,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get logger\n",
    "logger_geh = get_logger(\"GEH\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SLOLEKS = \"../data/sloleks/sloleks.csv\"\n",
    "GED = \"./models/ged_model_finetuned/\"\n",
    "GER = \"./models/ger_model_finetuned/\"\n",
    "GEC = \"./models/gec_model_finetuned/\"\n",
    "MAX_ERROR_RATE_SLOLEKS = 0.1\n",
    "MAX_NUMBER_OF_CORRECTIONS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Removes useless characters and splits text into sentences.\n",
    "\n",
    "    @param text: text that needs to be preprocessed\n",
    "    @return: a list of sentences\n",
    "    \"\"\"\n",
    "    # Tokenize the text into sentences\n",
    "    sentence_list = sent_tokenize(text)\n",
    "\n",
    "    # Tokenize each sentence into words\n",
    "    tokenized_sentence_list = [word_tokenize(sentence) for sentence in sentence_list]\n",
    "\n",
    "    # Remove stop words from each sentence\n",
    "    filtered_sentence_list = []\n",
    "    for index, sentence in enumerate(tokenized_sentence_list):\n",
    "        filtered_sentence = \" \".join([word for word in sentence if word.isalnum()])\n",
    "\n",
    "        # Check if the origin text contains punctuation\n",
    "        if sentence_list[index][-1] in string.punctuation:\n",
    "            filtered_sentence += sentence_list[index][-1]\n",
    "\n",
    "        filtered_sentence_list.append(filtered_sentence)\n",
    "\n",
    "    return filtered_sentence_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sloleks_tool(sentence):\n",
    "    \"\"\"\n",
    "    For every word in sentence checks if it is contained in the Sloleks lexicon.\n",
    "\n",
    "    @param sentence: a sentence that needs to be handled\n",
    "    @result: the percentage of grammatically incorrect words\n",
    "    \"\"\"\n",
    "    sloleks = pd.read_csv(SLOLEKS, keep_default_na=False)\n",
    "\n",
    "    # Tokenize each sentence into words\n",
    "    tokenized_sentence = word_tokenize(sentence)\n",
    "\n",
    "    number_of_incorrect_words = 0\n",
    "    number_of_all_words = len(tokenized_sentence)\n",
    "    for index, word in enumerate(tokenized_sentence):\n",
    "        if word in string.punctuation:\n",
    "            # Ignore punctuations\n",
    "            continue\n",
    "        elif (\n",
    "            # Check for the first words in the sentence (ignore case)\n",
    "            index == 0 and word not in sloleks.values and word.lower() in sloleks.values\n",
    "        ):\n",
    "            continue\n",
    "        elif word not in sloleks.values:\n",
    "            # Check if the word is in Sloleks lexicon\n",
    "            number_of_incorrect_words += 1\n",
    "\n",
    "    return number_of_incorrect_words / number_of_all_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(text):\n",
    "    \"\"\"\n",
    "    Grammatically handles the input text.\n",
    "\n",
    "    @param text: input text that user wants to handle\n",
    "    @return: grammatically handled text\n",
    "    \"\"\"\n",
    "    # Model, tokenizer and pipeline for GED\n",
    "    model_ged = AutoModelForSequenceClassification.from_pretrained(GED)\n",
    "    tokenizer_ged = AutoTokenizer.from_pretrained(GED)\n",
    "    pipeline_ged = TextClassificationPipeline(\n",
    "        model=model_ged, tokenizer=tokenizer_ged, task=\"Grammar Error Detection\"\n",
    "    )\n",
    "\n",
    "    # Model, tokenizer and pipeline for GER\n",
    "    model_ger = AutoModelForTokenClassification.from_pretrained(GER)\n",
    "    tokenizer_ger = AutoTokenizer.from_pretrained(GER)\n",
    "    pipeline_ger = TokenClassificationPipeline(\n",
    "        model=model_ger, tokenizer=tokenizer_ger, task=\"Grammar Error Recognition\"\n",
    "    )\n",
    "\n",
    "    # Model, tokenizer and pipeline for GEC\n",
    "    model_gec = AutoModelForSeq2SeqLM.from_pretrained(GEC)\n",
    "    tokenizer_gec = AutoTokenizer.from_pretrained(GEC)\n",
    "    pipeline_gec = Text2TextGenerationPipeline(\n",
    "        model=model_gec, tokenizer=tokenizer_gec, task=\"Grammar Error Correction\"\n",
    "    )\n",
    "\n",
    "    # Text preprocessing\n",
    "    unhandled_sentence_list = preprocess(text)\n",
    "    handled_sentence_list = []\n",
    "\n",
    "    # Repeat for every sentence\n",
    "    for sentence in unhandled_sentence_list:\n",
    "        handled_sentence = sentence\n",
    "\n",
    "        # Repeat for the max allowed number of corrections\n",
    "        for _ in range(MAX_NUMBER_OF_CORRECTIONS):\n",
    "            # Sloleks tool\n",
    "            sloleks_result = sloleks_tool(handled_sentence)\n",
    "\n",
    "            # GED\n",
    "            ged_result = pipeline_ged(handled_sentence)\n",
    "            logger_geh.info(\"GED result \" + str(ged_result))\n",
    "\n",
    "            # Check if the sentence is grammatically correct\n",
    "            if (\n",
    "                ged_result[0][\"label\"] == \"LABEL_1\"\n",
    "                and sloleks_result < MAX_ERROR_RATE_SLOLEKS\n",
    "            ):\n",
    "                # Sentence is grammatically correct\n",
    "                break\n",
    "\n",
    "            # GER\n",
    "            ger_result = pipeline_ger(handled_sentence)\n",
    "            logger_geh.info(\"GER result \" + str(ger_result))\n",
    "\n",
    "            # GEC\n",
    "            gec_result = pipeline_gec(handled_sentence)\n",
    "            logger_geh.info(\"GEC result \" + str(gec_result))\n",
    "\n",
    "            # Update the sentence\n",
    "            handled_sentence = \" \".join(\n",
    "                [\n",
    "                    corrected_sentence[\"generated_text\"]\n",
    "                    for corrected_sentence in gec_result\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        # Add the sentence to the final output\n",
    "        handled_sentence_list.append(handled_sentence)\n",
    "        logger_geh.info(sentence + \" -> \" + handled_sentence)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Grammar error handling\")\n",
    "    parser.add_argument(\n",
    "        \"-t\",\n",
    "        \"--text\",\n",
    "        metavar=\"path\",\n",
    "        required=True,\n",
    "        type=str,\n",
    "        help=\"Text you want to grammatically handle\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    main(args.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('slovko')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b7441cdf19e0d28b58859c3a7d82aad7fb7437a4f6af83da442de25c6af8e16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
